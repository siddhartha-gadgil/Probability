
<html>
<head>
<meta charset="utf-8">
   <meta http-equiv="X-UA-Compatible" content="IE=edge">
   <meta name="viewport" content="width=device-width, initial-scale=1">

<title> Probability Models and Stastics</title>
<link rel="icon" href="../IIScLogo.jpg">

<!-- Latest compiled and minified CSS  for Bootstrap -->
<link rel="stylesheet" href="../css/bootstrap.min.css">

<style type="text/css">
   body { padding-top: 60px; }
   .section {padding-top: 60px;}
   #arxiv {
     border-style: solid;
     border-width: 1px;
   }
</style>


  <!-- mathjax config similar to math.stackexchange -->



  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } },
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
  inlineMath: [ ['$', '$'] ],
  displayMath: [ ['$$', '$$'], ['\\[', '\\]' ]],
  processEscapes: true,
  skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  messageStyle: "none",
  "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
  });
  </script>
  <script type="text/javascript" async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML">
       </script>
</head>
<body>
    

<nav class="navbar navbar-default navbar-fixed-bottom">
    <div class="container-fluid">
      <!-- Brand and toggle get grouped for better mobile display -->
      <div class="navbar-header">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1" aria-expanded="false">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <span class="navbar-brand">Probability and Statistics (notes by Manjunath Krishnapur)</span>
      </div>

      <!-- Collect the nav links, forms, and other content for toggling -->
      <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">

        <ul class="nav navbar-nav navbar-right">
          <li><a href="index.html">Table of Contents</a></li>
          <li class="dropdown">
            <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false"> Probabibility (part 1) <span class="caret"></span></a>
            <ul class="dropdown-menu">
             <li><a href="chapter-1.html">1. What is statistics and what is probability?</a> </li>
<li><a href="chapter-2.html">2. Discrete probability spaces</a> </li>
<li><a href="chapter-3.html">3. Examples of discrete probability spaces</a> </li>
<li><a href="chapter-4.html">4. Countable and uncountable</a> </li>
<li><a href="chapter-5.html">5. On infinite sums</a> </li>
<li><a href="chapter-6.html">6. Basic rules of probability</a> </li>
<li><a href="chapter-7.html">7. Inclusion-exclusion formula</a> </li>
<li><a href="chapter-8.html">8. Bonferroni's inequalities</a> </li>
<li><a href="chapter-9.html">9. Independence - a first look</a> </li>
<li><a href="chapter-10.html">10. Conditional probability and independence</a> </li>
<li><a href="chapter-11.html">11. Independence of three or more events</a> </li>
<li><a href="chapter-12.html">12. Subtleties of conditional probability</a> </li>
            </ul>
          </li>

          <li class="dropdown">
            <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Probability (part 2) <span class="caret"></span></a>
            <ul class="dropdown-menu">
             <li><a href="chapter-13.html">13. Discrete probability distributions</a> </li>
<li><a href="chapter-14.html">14. General probability distributions</a> </li>
<li><a href="chapter-15.html">15. Uncountable probability spaces - conceptual difficulties</a> </li>
<li><a href="chapter-16.html">16. Examples of continuous distributions</a> </li>
<li><a href="chapter-17.html">17. Simulation</a> </li>
<li><a href="chapter-18.html">18. Joint distributions</a> </li>
<li><a href="chapter-19.html">19. Change of variable formula</a> </li>
<li><a href="chapter-20.html">20. Independence and conditioning of random variables</a> </li>
<li><a href="chapter-21.html">21. Mean and Variance</a> </li>
<li><a href="chapter-22.html">22. Makov's and Chebyshev's inequalities</a> </li>
<li><a href="chapter-23.html">23. Weak law of large numbers</a> </li>
<li><a href="chapter-24.html">24. Monte-Carlo integration</a> </li>
<li><a href="chapter-25.html">25. Central limit theorem</a> </li>
<li><a href="chapter-26.html">26. Poisson limit for rare events</a> </li>
<li><a href="chapter-27.html">27. Entropy, Gibbs distribution</a> </li>
            </ul>
          </li>

          <li class="dropdown">
            <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false"> Statistics <span class="caret"></span></a>
            <ul class="dropdown-menu">
             <li><a href="chapter-28.html">28. Introduction</a> </li>
<li><a href="chapter-29.html">29. Estimation problems</a> </li>
<li><a href="chapter-30.html">30. Properties of estimates</a> </li>
<li><a href="chapter-31.html">31. Confidence intervals</a> </li>
<li><a href="chapter-32.html">32. Confidence interval for the mean</a> </li>
<li><a href="chapter-33.html">33. Actual confidence by simulation</a> </li>
<li><a href="chapter-34.html">34. Hypothesis testing - first examples</a> </li>
<li><a href="chapter-35.html">35. Testing for the mean of a normal population</a> </li>
<li><a href="chapter-36.html">36. Testing for the difference between means of two normal populations</a> </li>
<li><a href="chapter-37.html">37. Testing for the mean in absence of normality</a> </li>
<li><a href="chapter-38.html">38. Chi-squared test for goodness of fit</a> </li>
<li><a href="chapter-39.html">39. Tests for independence</a> </li>
<li><a href="chapter-40.html">40. Regression and Linear regression</a> </li>
            </ul>
          </li>
        </ul>
      </div><!-- /.navbar-collapse -->
    </div><!-- /.container-fluid -->
  </nav>

  
<div class="container">
<h1 class="text-center bg-info">Chapter 11 : Independence of three or more events</h1>
<p>&nbsp;</p>



 <p class="text-justify">

<p>&nbsp;</p>
                <div id="theorem-69"><div class="panel panel-primary definition"> <div class="panel-heading">Definition 69 </div><div class="panel-body"> Events $A_{1},\ldots ,A_{n}$ in a common probability space are said to be independent if
$
\mathbf{P}\left(A_{i_{1} }\cap A_{i_{2} }\cap \ldots \cap A_{i_{m} }\right)=\mathbf{P}(A_{i_{1} })\mathbf{P}(A_{i_{2} })\ldots \mathbf{P}(A_{i_{m} })$ for every choice of $m\le n$ and every choice of $1\le i_{1} < i_{2} < \ldots  < i_{m}\le n$.
</div></div></div>
 The independence of $n$ events requires us to check $2^{n}$ equations (that many choices of $i_{1},i_{2},\ldots$). Should it not suffice to check that each pair of $A_{i}$ and $A_{j}$ are independent? The following example shows that this is not the case!
<p>&nbsp;</p>
                <div id="theorem-70"><div class="panel panel-info example"> <div class="panel-heading">Example 70 </div><div class="panel-body"> Let $\Omega=\{0,1\}^{n}$ with $p_{\underline{\omega}}=2^{-n}$ for each $\underline{\omega}\in \Omega$. Define the events $A=\{\underline{\omega}{\; : \;} \omega_{1}=0\}$, $A=\{\underline{\omega}{\; : \;} \omega_{2}=0\}$ and $C=\{\underline{\omega}{\; : \;} \omega_{1}+\omega_{2}=0 \mbox{ or }2\}$. In words, we toss a fair coin $n$ times and $A$ denotes the event that the first toss is a tail, $B$ denotes the event that the second toss is a tail and $C$ denotes the event that out of the first two tosses are both heads or both tails. Then $\mathbf{P}(A)=\mathbf{P}(B)=\mathbf{P}(C)=\frac{1}{4}$. Further,
\[\begin{aligned}
\mathbf{P}(A\cap B)=\frac{1}{4}, \; \mathbf{P}(B\cap C)=\frac{1}{4}, \; P(A\cap C)=\frac{1}{4}, \; \mathbf{P}(A\cap B\cap C)=\frac{1}{4}.
\end{aligned}\]
Thus,  $A,B,C$ are independent <em> pairwise</em>, but not independent by our definition because $\mathbf{P}(A\cap B\cap C)\not= \frac{1}{8}=\mathbf{P}(A)\mathbf{P}(B)\mathbf{P}(C)$.
 </p>
<p class="text-justify">
          
 Intuitively this is right. Knowing $A$ does not given any information about $C$ (similarly with $A$ and $B$ or $B$ and $C$), but knowing $A$ and $B$ tells us completely whether or not $C$ occurred! Thus is is right that the definition should not declare them to be independent.
</div></div></div>
 </p>
           
 <p class="text-justify">
<p>&nbsp;</p>
                <div id="theorem-71"><div class="panel panel-warning exercise"> <div class="panel-heading">Exercise 71 </div><div class="panel-body"> Let $A_{1},\ldots ,A_{n}$ be events in a common probability space. Then, $A_{1}, A_{2},\ldots ,A_{n}$ are independent if and only if the following equalities hold: For each $i$, define $B_{i}$ as $A_{i}$ and $A_{i}^{c}$. Then
\[\begin{aligned}
\mathbf{P}(B_{1}\cap B_{2}\cap \ldots \cap B_{n})=\mathbf{P}(B_{1})\mathbf{P}(B_{2})\ldots \mathbf{P}(B_{n}).
\end{aligned}\]
</div></div></div>
<strong>Note :</strong> This should hold for any possible choice of $B_{i}$s. In other words, the system of $2^{n}$ equalities in the definition of independence may be replaced by this new set of $2^{n}$ equalities. The latter system has the advantage that it immediately tells us that if $A_{1},\ldots ,A_{n}$ are independent, then $A_{1},A_{2}^{c}, A_{3},\ldots $ (for each $i$ choose $A_{i}$ or its complement) are independent.
 </p>
<p class="text-justify">
          
 
 </p>
           

<div class="pull-right"><a href="chapter-12.html" class="btn btn-primary">Chapter 12. Subtleties of conditional probability</a></div>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>

</div>
<script type="text/javascript" src="../js/jquery-2.1.4.min.js"></script>
 <script type="text/javascript" src='../js/bootstrap.min.js'></script>
<script type="text/javascript" src='../js/probability.js'></script>
<script type="text/javascript">
      Illustrations.main();
    </script>

  </body>
</html>
    